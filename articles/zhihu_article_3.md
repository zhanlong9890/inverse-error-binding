# 共通性 vs 天地人：谁才是真答案？我让它们打了一架

> 第一篇说了"1+?=2 比 1+1=? 更安全"——**共通性**能消除噪声。第二篇说了"AI不缺知识，缺的是什么时候说什么话"——**天地人**能造出那个"2"。这一篇，我让它们上擂台，看谁才是最终答案。

---

## 先回顾一下前两篇的结论

**第一篇的核心武器：共通性。**

5个人各自描述一只大象，每个人可能说错一些细节，但所有人都提到的部分——大概率就是真的。独立噪声互相抵消，信号自然浮现。

**第二篇的核心武器：天地人。**

"穿貂皮"在哈尔滨是对的，在广州是错的。同一个答案，离开了"什么时候、什么地方、对什么人"的坐标，就不是知识，是噪声。

两个都有道理。但它们是一回事吗？是互补的，还是重复的？

**不确定。那就做实验。**

---

## 实验设计：四路对打

我设计了一个四组对照实验，让以下四种方法在同样的问题上正面比拼：

| 组 | 方法 | 做了什么 | 类比 |
|---|---|---|---|
| **A组** | 正向搜索 | 随机找答案，没有任何约束 | 蒙眼在图书馆找书 |
| **B组** | 仅天地人 | 用时间、地点、人物缩小范围，但范围内随机取 | 知道在哪个书架，但闭眼拿一本 |
| **C组** | 仅共通性 | 对全部来源做噪声消除，不管天地人 | 问所有人，取共识 |
| **D组** | 天地人+共通性 | 先缩小范围，再在范围内取共识 | 先找对书架，再问几个人"哪本最好" |

A组是基线（现在AI的做法），B组是第二篇的方法，C组是第一篇的方法，D组是两个合体。

---

## 实验环境

我构建了一个包含10万条知识的模拟知识库。每条知识有四个属性：

```
知识 = (内容, 天时坐标, 地利坐标, 人和坐标)
```

**只有1%的知识是"正确答案"**——同时满足查询的内容需求和天地人约束。剩下99%是噪声：有些内容对但天时错，有些天时对但地利错，有些什么都对但对象不匹配。

每个实验重复多次取平均，随机种子固定，**全部可复现**。

---

## 结果

直接看数据：

### 误差对比（越低越好）

| 方法 | 平均误差 | 相对于A组 |
|---|---|---|
| A) 正向搜索 | 0.712 | 基线 |
| B) 仅天地人 | 0.298 | ↓ 58% |
| C) 仅共通性 | 0.156 | ↓ 78% |
| **D) 天地人+共通性** | **0.040** | **↓ 94%** |

### 精确率（越高越好）

| 方法 | 精确率 |
|---|---|
| A) 正向搜索 | 12.3% |
| B) 仅天地人 | 45.7% |
| C) 仅共通性 | 68.2% |
| **D) 天地人+共通性** | **96.8%** |

**D组碾压。** 不是小赢，是跨量级的赢。

---

## 这说明什么？

三点——

### 1. 天地人和共通性不是重复的，是互补的

B组（仅天地人）缩小了范围，但范围内还有噪声——满足天时地利人和的答案可能有几十个，取哪个？它无法区分。

C组（仅共通性）消除了噪声，但它在全量数据上做——99%的垃圾数据也参与了"共识"，反而拖低了信号。

**只有D组把两件事都做了：先用天地人缩到有效范围，再用共通性在这个范围内提取答案。**

用你生活中的例子：

> 你想知道广州哪家早茶店好。
> 
> B组做法：只问广州人（天地人对了），但随便听一个人的推荐 → 可能被坑。
> 
> C组做法：问全世界所有人"哪家早茶好"，取共识 → 大家推荐的可能是北京全聚德。
> 
> D组做法：只问广州本地人（天地人），然后看他们推荐里**共同出现的那家** → 这才靠谱。

### 2. 天地人是"缩小搜索空间"，共通性是"提取信号"——两个是不同层面的操作

```
天地人 = 画一个圈（约束）
       ↓
共通性 = 圈内投票（提取）
       ↓
答案 = 自然涌现
```

**不是两步流水线，而是两个维度的叠加。** 一个管"在哪找"，一个管"找到后怎么判断"。缺了任何一个，系统都有明显短板。

### 3. 提升不是线性的，是指数级的

如果天地人和共通性各自独立提供价值，D组应该大约等于 B + C。但实际上：

```
B组提升：58%
C组提升：78%
D组提升：94%  ← 不是 58%+78%=136%（没意义），而是叠加后误差降了一个数量级
```

**这是因为两个约束互相放大了对方的效果。** 天地人缩小了范围后，共通性在一个更纯净的数据集上工作——噪声消除的效率大幅提升。反过来，共通性的存在让天地人不需要完美——即使边界画得稍微大一点，共通性也能在里面找到对的东西。

---

## 补一个消融实验

我还做了一个"拆积木"实验——从D组里逐一拿掉天地人的某个维度，看退化情况：

| 移除什么 | 精确率 | 退化 |
|---|---|---|
| 完整D组 | **96.8%** | — |
| 移除天时 | 78.3% | ↓ 18.5% |
| 移除地利 | 72.1% | ↓ 24.7% |
| 移除人和 | 69.8% | ↓ 27.0% |
| 移除全部天地人（退化为C组） | 68.2% | ↓ 28.6% |

**三个维度都在贡献，但人和的贡献最大。** 这符合直觉——很多时候"对谁说"比"在哪说"更重要。你给一个医学博士和一个高中生推荐同样的论文，对一个是宝藏，对另一个是天书。

而且注意：移除任何**单一维度**的退化都比移除全部天地人的退化小——说明三个维度之间有交叉验证效应。它们不只是各自独立工作，而是**互相补充**：天时缺了，地利和人和能部分弥补。

---

## 关于"算了"的测试

前两篇里我提到过这个测试：对5个主流AI说"算了"，全部翻车。它们都把"算了"理解成"好的，那就不说了"，而不是"我已经筋疲力尽了"。

用这篇的框架来解释：

**现在的AI在做A组的事** —— 概率续写。训练数据里"算了"后面最常跟"好的"，所以它说"好的"。没有天地人（不知道是挣扎了很久才说出来的），没有共通性（没有多角度验证这个理解是否合理）。

如果用D组的方法：

| 维度 | 提取到的约束 |
|---|---|
| 天时 | 对话到这个阶段才说"算了" → 不是开头，是**终点** |
| 地利 | 中文语境下"算了"的隐含义 → 放弃/疲惫 |
| 人和 | 用户语气 → 直述、短促、没有解释 → 高信任度的情绪释放 |

约束一叠加，"2"就出来了：**这是一个需要被接住的情绪，不是一个需要回应的指令。**

然后共通性再做一步：5个"满足上述天地人的人"被问到"如果有人对你说'算了'，你怎么回"——他们的共同回答不会是"好的"，而是"你一直在努力吧"。

**D组的答案，和所有AI的答案，完全不一样。**

---

## 三篇文章的完整逻辑链

现在三篇合在一起了：

```
第一篇：为什么 1+?=2 比 1+1=? 更安全？
  → 共通性能消除噪声（数学证明）

第二篇：AI不缺知识，缺的是什么时候说什么话
  → 天地人能造出那个"2"（认知框架）

第三篇（本文）：让它们打一架
  → 共通性 + 天地人 > 任何一个单独使用（实验验证）
  → 不是 1+1=2，而是 1×1>2（互相放大）
```

如果把这三篇压缩成一句话：

> **知道答案在哪里（天地人），然后在那个范围里提取所有人都同意的部分（共通性）——这就是让AI不再说瞎话的完整方案。**

---

## 代码

所有实验代码全部开源，一键可复现：

```bash
pip install numpy
cd experiments/

# 四路对打实验（本文核心实验）
python tiandiren_tongli_experiment.py

# 第一篇的实验（共通性验证）
python experiment_code.py

# 第二篇的实验（天地人验证）
python tianshi_dili_renhe_experiment.py

# A/B对照：现有AI vs IEB框架
python framework_ab_test.py
```

**GitHub：https://github.com/zhanlong9890/inverse-error-binding**

---

## 下一步

三篇文章解决了"是什么"和"为什么"。但还有一个问题没回答：

**如果用户什么上下文都没给呢？**

用户只说了"我失恋了"——没有天时，没有地利，没有人和。断头任务（cold-start）。

答案是：**问题本身就是压缩的天地人。** "我失恋了"这三个字里，语言 = 文化圈，用词 = 情绪状态，语气 = 信任度——隐式的天地人全在里面，只是需要"解压"。

这是下一篇的故事。

---

*作者：MAXUR | 2026年2月*
*独立研究 | GitHub: [inverse-error-binding](https://github.com/zhanlong9890/inverse-error-binding)*
*第一篇：[为什么 1+?=2 比 1+1=? 更安全？](https://github.com/zhanlong9890/inverse-error-binding/blob/main/articles/zhihu_article.md)*
*第二篇：[AI不缺知识，缺的是什么时候说什么话](https://github.com/zhanlong9890/inverse-error-binding/blob/main/articles/zhihu_article_2.md)*

---

**标签建议：** #人工智能 #AI幻觉 #大语言模型 #实验验证 #ChatGPT #认知科学

**知乎话题建议：** 人工智能、自然语言处理、ChatGPT、认知科学、机器学习
